{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file presents a pipeline to classify the bags\n",
    "\n",
    "The first step is to do a PCA with the build images from the bags initially to reduce the feature dimensionalty. The second step is an SVM to classify in between the three bags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import sklearn, random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the data of the detected bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the paths to all the detected bags\n",
    "path_to_bags = os.path.join(os.getcwd(), 'data/processed_bags')\n",
    "bags_to_label = {'mixed_recycling':0, 'general_waste':1, 'green_sack':2}\n",
    "all_paths = [os.path.join(path_to_bags, form + '/' + index) for form in bags_to_label for index in os.listdir(os.path.join(path_to_bags, form))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(image, angle):\n",
    "    '''This function rotates an image, for data augmentation.\n",
    "    input:\n",
    "        - image, np.array of the image to be rotated\n",
    "        - image, np.array of the rotated image'''\n",
    "    \n",
    "    # randomly select the angle\n",
    "    angle = int(random.uniform(-angle, angle))\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # create the rotation matrix\n",
    "    T = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "    \n",
    "    # rotate the image\n",
    "    image = cv2.warpAffine(image, T, (w, h))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_iterator(train_val_ind, n_splits=5):\n",
    "    '''This function creates a cross validation iterator which takes into account the\n",
    "    difference between the training and validation set. Allows to select the transfomed/augmented\n",
    "    instance of the training set, and only the untouched examples for the validation set.\n",
    "    input:\n",
    "        - train_val_ind, list, indices of the train and validation datasets.\n",
    "        - n_splits, int, number of folds\n",
    "    output:\n",
    "        - tuple(cv), tuple of lists, iterator for the cross validation.'''\n",
    "    \n",
    "    # initialise the parameters\n",
    "    kf = KFold(n_splits)\n",
    "    cv = []\n",
    "    \n",
    "    # add the respective indices for each of the dataset\n",
    "    for train, test in kf.split(train_val_ind):\n",
    "        # multiply by 4 because of the three transforms added for each image\n",
    "        new_train = 4*np.array(train)\n",
    "        new_test = 4*np.array(test)\n",
    "        full_train = new_train\n",
    "        \n",
    "        # add indices of the transforms for each example of the training set\n",
    "        for i in range(1, 4):\n",
    "            full_train = np.append(full_train, new_train+i)\n",
    "        \n",
    "        # build the iterator\n",
    "        cv.append((full_train, new_test))\n",
    "        \n",
    "    return tuple(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_transforms(all_paths):\n",
    "    '''This function creates and saves the augmentations for each image.\n",
    "    input:\n",
    "        - all_paths, list of all the paths leading to the images\n",
    "    output:\n",
    "        - X_transformed, np.array of the data of the transformed images\n",
    "        - y_transformed, np.array of the labels of the transformed images'''\n",
    "    img_data = np.empty((0, 7500))\n",
    "    img_label = np.empty((0, 7500))\n",
    "    \n",
    "    for path in all_paths:\n",
    "        image = cv2.imread(path)\n",
    "        img_flat = np.ndarray.flatten(image).reshape((1,-1))\n",
    "        \n",
    "        # applying transforms for data augmentation\n",
    "        img_rot_flat = np.ndarray.flatten(rotation(image, 20)).reshape((1,-1))\n",
    "        img_flippedh_flat = np.ndarray.flatten(cv2.flip(image, 1)).reshape((1,-1))\n",
    "        img_flippedv_flat = np.ndarray.flatten(cv2.flip(image, 0)).reshape((1,-1))\n",
    "        \n",
    "        # gettinf the data into the arrays\n",
    "        img_data = np.append(img_data, np.array([img_flat, img_flippedv_flat, img_rot_flat, img_flippedh_flat]).reshape((4, 7500)), axis=0)\n",
    "        label = bags_to_label[path.split('/')[-2]]\n",
    "        img_label = np.append(img_label, np.array([label, label, label, label]).reshape((4, 1)))\n",
    "\n",
    "\n",
    "    np.save('data/tranformed/transformed_bags_data.npy', img_data)\n",
    "    np.save('data/tranformed/transformed_bags_labels.npy', img_label)\n",
    "\n",
    "    X_transformed = np.load('data/tranformed/transformed_bags_data.npy')\n",
    "    y_transformed = np.load('data/tranformed/transformed_bags_labels.npy').reshape(-1, 1)\n",
    "    \n",
    "    return X_transformed, y_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(indices, all_paths, train):\n",
    "    '''Gives the data for the requested images.\n",
    "    input:\n",
    "        - indices, list of required indices\n",
    "        - all_paths, list of the paths to the images\n",
    "        - train, str, to say if the augmentations are required or not\n",
    "    output:\n",
    "        - X_transformed, np.array of the relevant images\n",
    "        - y_transformed, np.array of the relevant labels'''\n",
    "    X_transformed = np.load('transformed_bags_data.npy')\n",
    "    y_transformed = np.load('transformed_bags_labels.npy').reshape(-1, 1)\n",
    "    if train=='train':\n",
    "        new = 4*np.array(indices)\n",
    "        full_indices = new\n",
    "        for i in range(1, 4):\n",
    "            full_indices = np.append(full_indices, new+i)\n",
    "        return X_transformed[full_indices, :], y_transformed[full_indices, :]\n",
    "    else:\n",
    "        return X_transformed[4*np.array(indices), :], y_transformed[4*np.array(indices), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following section provides the code for a cross validation and hyper-parameter tuning over the images. The first set proves the expected results on a test set when performing the hyper-parameter tuning pipeline.\n",
    "\n",
    "A PCA is applied on the images to perform dimensionality reduction. These are then used as featrues for an SVM to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 4., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.mkdir('data/tranformed/')\n",
    "create_and_save_transforms(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the hyper-parameter tuning by providing the score on the test samples\n",
    "def evaluate_hp_tuning(cv, all_paths):\n",
    "    '''This fucntion serves to evaluate the perfomance of the hyper parameter tuning \n",
    "    on each of the cross validations. \n",
    "    input:\n",
    "        - cv, tuple iterator for the cross validation\n",
    "        - all_paths, list of all the paths to the untouched images\n",
    "    output:\n",
    "        - scores, array of the scores for each cross validation\n",
    "        - mean, float, mean of the scores\n",
    "        - var, flaot, variance of the scores'''\n",
    "    scores = []\n",
    "    for ind, (train_val_ind, test_ind) in enumerate(cv):\n",
    "        pca = PCA()\n",
    "        svm = SVC()\n",
    "        std1 = StandardScaler()\n",
    "        std2 = StandardScaler()\n",
    "\n",
    "        pipe = Pipeline(steps=[('std1', std1), ('pca', pca), ('std2', std2), ('svm', svm)])\n",
    "\n",
    "        param_grid = {\n",
    "        'pca__n_components': [5, 15, 30, 45, 60, 75],\n",
    "        'svm__C': [1, 30, 50, 100, 150],\n",
    "        'svm__kernel':['rbf', 'poly']\n",
    "        }\n",
    "        \n",
    "        cv_in = get_cv_iterator(train_val_ind, n_splits=10)\n",
    "\n",
    "        X_train_val, y_train_val = get_transforms(train_val_ind, all_paths, 'train')\n",
    "        X_test, y_test = get_transforms(test_ind, all_paths, 'test')\n",
    "\n",
    "        search_svm = GridSearchCV(pipe, param_grid, cv=cv_in, n_jobs=-1)\n",
    "        search_svm.fit(X_train_val, y_train_val.ravel())\n",
    "\n",
    "        scores.append(search_svm.score(X_test, y_test.ravel()))\n",
    "    \n",
    "    # Average scores obtained on test samples and their variance\n",
    "    return scores, np.array(scores).mean(), np.array(scores).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "source": [
    "# creating folds for the full cross validation, shuffling paths because as for now they are ordered per class\n",
    "random.seed(0)\n",
    "random.shuffle(all_paths)\n",
    "cv = KFold(n_splits=10).split(range(len(all_paths)))\n",
    "results, mean, var = evaluate_hp_tuning(cv, all_paths)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final cross-validation over all test samples - provides hyper-parameters for porduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hp_production(all_paths):\n",
    "    '''Perfom final hyperparamter tuning to get the final score and final model for test time.\n",
    "    input:\n",
    "        - all_paths, list of all the paths leading to the images\n",
    "    output:\n",
    "        - params, dict, parameters of the best model\n",
    "        - best_score, float, mean best score of the best model over the cross validation\n",
    "    '''\n",
    "    X, y = get_transforms(list(range(len(all_paths))), all_paths, 'train')\n",
    "    cv = get_cv_iterator(range(len(all_paths)), n_splits=5)\n",
    "    \n",
    "    pca = PCA()\n",
    "    svm = SVC()\n",
    "    std1 = StandardScaler()\n",
    "    std2 = StandardScaler()\n",
    "    \n",
    "    pipe_final = Pipeline(steps=[('std1', std1), ('pca', pca), ('std2', std2), ('svm', svm)])\n",
    "    \n",
    "    param_grid = {\n",
    "    'pca__n_components': [5, 10, 50, 100],\n",
    "    'svm__C': [1, 10, 30, 100, 150, 200],\n",
    "    'svm__kernel':['rbf', 'poly']\n",
    "    }\n",
    "    \n",
    "    search_final = GridSearchCV(pipe_final, param_grid, cv=cv, n_jobs=-1)\n",
    "    search_final.fit(X, y.ravel())\n",
    "    \n",
    "    return search_final.best_params_, search_final.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, score = get_hp_production(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7982758620689656\n"
     ]
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
